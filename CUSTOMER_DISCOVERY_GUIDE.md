# Claude Mail - Customer Discovery Interview Guide

## Interview Objectives

1. **Validate problem:** Do prospects struggle with email personalization at scale?
2. **Validate pivots:** Are our strategic pivots aligned with real needs?
3. **Validate pricing:** What would prospects pay for this solution?
4. **Validate positioning:** Does "Campaign OS" resonate better than "Email Generator"?
5. **Identify must-haves:** Which features are critical for MVP?

**Target:** 10-15 interviews
**Duration:** 30-45 minutes each
**Format:** Video call (Zoom, Google Meet)

---

## Ideal Interview Candidates

### Tier 1: Agencies & Consultants (Priority)
- Marketing agencies doing B2B outreach
- Sales consulting firms
- Lead generation agencies
- Fractional CMOs/VPs

**Why:** High volume, sophisticated needs, willing to pay

### Tier 2: B2B SaaS Founders
- Early-stage founders (Seed to Series A)
- Founder-led sales still active
- Technical products

**Why:** Understand personalization value, price-sensitive but quality-focused

### Tier 3: Sales Development Leaders
- VPs of Sales at B2B companies
- Sales Development Managers
- Revenue Operations

**Why:** Scale needs, budget authority, measurable ROI requirements

---

## Pre-Interview Setup

### Screening Questions (Email/Form)
1. What's your current role and company?
2. How many cold emails do you send per month?
3. What tools do you currently use for email outreach?
4. What's your biggest challenge with cold email?
5. Would you be open to a 30-minute call to discuss your outreach workflow?

### Materials to Prepare
- [ ] 1-page concept overview (visual)
- [ ] Sample output (generated campaign)
- [ ] Competitive comparison matrix
- [ ] Pricing options (3 tiers)

---

## Interview Script

### Introduction (3 minutes)

> "Hi [Name], thanks for taking the time. I'm researching how B2B teams handle personalized outreach at scale. I'm not selling anything today—just trying to understand your workflow and challenges. Everything you share is confidential. Sound good?"

**Set expectations:**
- 30-45 minutes
- No right answers, just honest feedback
- Can stop anytime
- Will share research insights afterward

---

### Part 1: Current State (10 minutes)

**Goal:** Understand their current workflow and pain points

**Questions:**

1. **Volume & Process**
   - "Walk me through how you handle cold email outreach today."
   - "How many campaigns do you run per month?"
   - "How many leads per campaign, typically?"

2. **Tools & Stack**
   - "What tools do you use?" (Smartwriter, Lyne, manual, etc.)
   - "What do you like about [tool]?"
   - "What frustrates you about [tool]?"

3. **Personalization Approach**
   - "How personalized are your emails?" (scale of 1-10)
   - "How do you research prospects?"
   - "How long does it take to research and write one personalized email?"

4. **Pain Points** (CRITICAL)
   - "What's the biggest challenge you face with email outreach?"
   - "What would have to happen for you to rate your outreach a 10/10?"
   - "What takes the most time in your current process?"

**Listen for:**
- Time constraints
- Quality vs quantity tradeoffs
- Repetition/content fatigue
- Personalization depth challenges
- Campaign orchestration difficulties

---

### Part 2: Value Delivery & Reciprocity (8 minutes)

**Goal:** Validate reciprocity-first approach

**Questions:**

5. **Content Sharing**
   - "Do you share valuable content/insights in your emails, or focus on pitching?"
   - "What types of assets do you typically share?" (case studies, tools, insights)
   - "How do you decide what to share with each prospect?"

6. **Repetition Concerns**
   - "Do you ever worry about sending the same content to a prospect multiple times?"
   - "How do you track what you've already shared with someone?"
   - "Has a prospect ever called you out for repeating yourself?"

7. **Multi-Touch Campaigns**
   - "How many emails do you typically send in a sequence?"
   - "How do you decide when to stop outreach?"
   - "Do you adjust your approach based on prospect characteristics?"

**Listen for:**
- Value-first mindset (or lack thereof)
- Memory/tracking challenges
- Campaign sophistication
- Adaptive vs rigid sequences

---

### Part 3: Concept Testing (12 minutes)

**Goal:** Get reaction to Claude Mail concept

**Setup:**
> "I'd like to show you a concept we're exploring and get your honest reaction. Remember, there are no right answers—your candid feedback is most valuable."

**Show 1-page concept overview**

8. **Initial Reaction**
   - "What's your first reaction?"
   - "What stands out to you?"
   - "What questions come to mind?"

9. **Feature Validation**
   - "Which of these features would be most valuable to you?" (show list)
   - "Which features seem unnecessary or over-engineered?"
   - "What's missing that you'd need to see?"

**Feature List to Test:**
- [ ] Multi-session memory (never repeat content)
- [ ] Psychographic analysis (beyond job title/company)
- [ ] Dynamic campaign length (2-7 emails based on prospect)
- [ ] Tone calibration (casual to formal)
- [ ] Asset library integration (case studies, tools, insights)
- [ ] Performance feedback loop (learning system)

10. **Pivot Validation** (CRITICAL)
    - "Would you rather have a tool that generates individual emails, or orchestrates entire campaigns?"
    - "Would you provide prospect data, or expect the tool to scrape it?"
    - "Is a fixed 3-email sequence fine, or do you need flexibility?"

**Listen for:**
- Feature priority
- Pivot alignment
- Deal-breakers
- Excitement level

---

### Part 4: Competitive Positioning (7 minutes)

**Goal:** Understand how Claude Mail compares

**Show competitive comparison matrix**

11. **Competitive Context**
    - "How does this compare to [tool you currently use]?"
    - "What would make you switch from [current tool] to this?"
    - "Would this replace your current tool, or complement it?"

12. **Positioning Test**
    - "If you had to describe this to a colleague, would you say it's an 'email generator' or a 'campaign orchestration system'?"
    - "What's the key differentiator you'd focus on?"

**Listen for:**
- Switching barriers
- Positioning resonance
- Differentiation perception

---

### Part 5: Pricing & Willingness to Pay (5 minutes)

**Goal:** Validate pricing model

13. **Current Spend**
    - "What do you currently pay for your email outreach tools?" (monthly)
    - "What else is in your sales/marketing tech stack?"

14. **Value Perception**
    - "If this tool saved you 5 hours per week and improved reply rates by 2x, what would it be worth to you?"
    - "Would you prefer pricing based on email volume, campaigns, or flat monthly fee?"

15. **Pricing Options** (Show 3 tiers)
    - "Which tier would you choose?"
    - "Does any tier seem overpriced or underpriced?"
    - "What would push you from [lower tier] to [higher tier]?"

**Pricing Options to Test:**
- Free: 50 emails/month, 1 campaign
- Pro: $149/mo - 500 emails, unlimited campaigns
- Agency: $399/mo - 2000 emails, team features

**Listen for:**
- Price anchoring
- Tier fit
- Budget constraints
- Value perception

---

### Part 6: Adoption & Implementation (5 minutes)

**Goal:** Understand onboarding and adoption barriers

16. **Getting Started**
    - "If you signed up today, what would your first use case be?"
    - "How long would you expect to take from signup to first campaign?"
    - "Would you need training, or expect it to be self-service?"

17. **Team Dynamics**
    - "Who else on your team would need access?"
    - "Who would make the buying decision?"
    - "What would you need to justify this purchase internally?"

**Listen for:**
- Onboarding expectations
- Decision-making process
- Team collaboration needs

---

### Closing (3 minutes)

18. **Final Thoughts**
    - "Is there anything I didn't ask that I should have?"
    - "What would make this a must-have vs nice-to-have for you?"

19. **Next Steps**
    - "Would you be interested in trying an early version?"
    - "Can I follow up with you as we develop this?"
    - "Do you know anyone else who'd be valuable to talk to?"

**Thank them:**
- Offer to share research insights
- Ask permission to follow up
- Send thank-you email with resources

---

## Post-Interview Analysis

### Rate Each Interview (1-5)

**Problem Severity:** How painful is their current state?
- 1 = No real problem
- 5 = Desperate for solution

**Solution Fit:** How well does Claude Mail solve their problem?
- 1 = Not a fit
- 5 = Perfect fit

**Buying Intent:** How likely are they to pay?
- 1 = Would never buy
- 5 = Ready to buy now

**Ideal Customer:** Are they in our target ICP?
- 1 = Wrong ICP
- 5 = Perfect ICP

### Key Insights to Extract

For each interview, document:
- [ ] Top 3 pain points mentioned
- [ ] Most exciting feature
- [ ] Least exciting feature
- [ ] Pricing reaction
- [ ] Pivot validation (yes/no for each)
- [ ] Deal-breakers identified
- [ ] Unexpected insights

---

## Synthesis Framework

### After 10 Interviews, Answer:

**Problem Validation:**
- [ ] Do 7+ people have the problem we're solving?
- [ ] Is it painful enough to pay for? (8+/10 pain)
- [ ] Is our solution 10x better than current alternatives?

**Feature Prioritization:**
- Which features were mentioned most often as "must-haves"?
- Which features got the strongest reactions?
- Which features can we cut for MVP?

**Pivot Validation:**
- Campaign orchestration vs email generator: Which resonated?
- User-provided data vs scraping: What do they prefer?
- Dynamic vs fixed email count: What do they need?

**Pricing Validation:**
- What's the average willingness to pay?
- Which tier did most people choose?
- Are we leaving money on the table or overpriced?

**Go/No-Go Decision:**
- [ ] 70%+ of interviewees would pay $99+/mo
- [ ] Clear differentiation from competitors
- [ ] MVP feature set validated
- [ ] Target customer profile confirmed

---

## Interview Tracker

| # | Name | Company | Role | Date | Rating | Key Insight | Follow-up? |
|---|------|---------|------|------|--------|-------------|------------|
| 1 | | | | | /20 | | |
| 2 | | | | | /20 | | |
| 3 | | | | | /20 | | |
| 4 | | | | | /20 | | |
| 5 | | | | | /20 | | |
| 6 | | | | | /20 | | |
| 7 | | | | | /20 | | |
| 8 | | | | | /20 | | |
| 9 | | | | | /20 | | |
| 10 | | | | | /20 | | |

**Rating:** Problem Severity (5) + Solution Fit (5) + Buying Intent (5) + Ideal Customer (5) = /20

---

## Red Flags to Watch For

⚠️ **Problem not painful enough**
- "That would be nice to have..."
- "I can work around it..."
- No emotional response to pain points

⚠️ **Solution doesn't resonate**
- Lukewarm reaction to concept
- Lots of "but what about..." objections
- Doesn't see clear differentiation

⚠️ **Price resistance**
- Immediate pushback on pricing
- Current spend is much lower
- Focus on "trying free version first"

⚠️ **Switching barriers too high**
- Locked into current contracts
- Too much effort to switch
- Integration requirements complex

⚠️ **Wrong ICP**
- Use case doesn't match our vision
- Budget too low
- Volume too low/high for our model

---

## Success Criteria

**Strong Signal (Proceed to MVP):**
- 7+/10 interviews rate problem as 8+/10 painful
- 6+/10 interviews say they'd pay $99+/mo
- Clear consensus on must-have features
- Competitive differentiation validated
- Multiple people ask "When can I use this?"

**Weak Signal (Pivot Required):**
- Problem not painful enough (<6/10)
- Pricing resistance across the board
- Feature confusion/lack of consensus
- No clear differentiation from competitors
- No one volunteers to be design partner

**No Signal (Stop/Rethink):**
- <5/10 interviews have the problem
- No willingness to pay
- Better alternatives exist
- Market not ready

---

## Next Steps After Interviews

1. **Synthesize findings** (1-2 days)
2. **Update product strategy** based on insights
3. **Refine MVP scope** based on must-haves
4. **Adjust pricing** if needed
5. **Secure design partners** from high-rated interviews
6. **Begin development** if signals are strong

---

**Remember:** The goal is to learn, not to validate assumptions. Be open to pivoting or even stopping if the signals aren't there.
